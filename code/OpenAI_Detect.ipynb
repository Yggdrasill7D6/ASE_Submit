{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tiktoken.get_encoding() to load an encoding by name.\n",
    "\n",
    "The first time this runs, it will require an internet connection to download. Later runs won't need an internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tiktoken.encoding_for_model() to automatically load the correct encoding for a given model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_token.txt\", 'r') as fp:\n",
    "    openai_token = fp.readline()\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = openai_token\n",
    "# Set the environment variable\n",
    "#os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(sentence):\n",
    "    return ''.join(char for char in sentence if ord(char) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/prompt/prompt_system_etd_V3.txt', 'r') as fp:\n",
    "    etd_system = fp.readlines()\n",
    "    \n",
    "with open('../data/prompt/prompt_system_ps_V3.txt', 'r') as fp:\n",
    "    ps_system = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(etd_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_etd_len = num_tokens_from_string(\" \".join(etd_system), \"cl100k_base\")\n",
    "total_user_etd_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(ps_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_user_ps_len = num_tokens_from_string(\" \".join(ps_system), \"cl100k_base\")\n",
    "total_user_ps_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = pd.read_csv(\"../data/issue.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_clean = [remove_non_ascii(issue) for issue in df_issue[\"issue\"]]\n",
    "df_issue[\"issue\"] = issue_clean\n",
    "df_issue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for random example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose either run ETD or PS\n",
    "# df_etd_example = pd.read_csv(\"../data/prompt/example/etd_example_V3.csv\")\n",
    "df_ps_example = pd.read_csv(\"../data/prompt/example/ps_example_V3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etd_randexample = df_etd_example[df_etd_example[\"5_1examples\"]==1]\n",
    "\n",
    "chat_issue = list(df_etd_randexample[\"issue\"].values)\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_output = list(df_etd_randexample[\"output\"].values)\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps_randexample = df_ps_example[df_ps_example[\"5_1examples\"]==1]\n",
    "\n",
    "chat_issue = list(df_ps_randexample[\"issue\"].values)\n",
    "chat_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_output = list(df_ps_randexample[\"output\"].values)\n",
    "chat_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_string,output_string in zip(chat_issue,chat_output):\n",
    "    total_user_etd_len += num_tokens_from_string(user_string,\"cl100k_base\")\n",
    "    total_user_etd_len += num_tokens_from_string(output_string,\"cl100k_base\")\n",
    "    \n",
    "print(\"ETD total input token:\",total_user_etd_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_string,output_string in zip(chat_issue,chat_output):\n",
    "    total_user_ps_len += num_tokens_from_string(user_string,\"cl100k_base\")\n",
    "    total_user_ps_len += num_tokens_from_string(output_string,\"cl100k_base\")\n",
    "    \n",
    "print(\"PS total input token:\",total_user_ps_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ans1= []\n",
    "start_i = 0\n",
    "flag = True\n",
    "while flag:\n",
    "    try:\n",
    "        for i in range(start_i,len(df_issue),1):\n",
    "            issue = df_issue.loc[i][\"issue\"]\n",
    "            input_str = \"\\\"\\\"\\\" {} \\\"\\\"\\\"\".format(issue)\n",
    "    \n",
    "            result = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4o\",\n",
    "#                 model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "#             {\"role\": \"system\", \"content\": \" \".join(etd_system)},\n",
    "            {\"role\": \"system\", \"content\": \" \".join(ps_system)},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[0]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[0]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[1]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[1]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[2]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[2]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[3]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[3]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[4]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[4]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[5]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[5]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[6]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[6]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[7]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[7]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[8]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[8]},\n",
    "            {\"role\": \"user\", \"content\": chat_issue[9]},\n",
    "            {\"role\": \"assistant\", \"content\": chat_output[9]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[10]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[10]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[11]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[11]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[12]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[12]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[13]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[13]},\n",
    "#             {\"role\": \"user\", \"content\": chat_issue[14]},\n",
    "#             {\"role\": \"assistant\", \"content\": chat_output[14]},\n",
    "            {\"role\": \"user\", \"content\": input_str},\n",
    "                ],\n",
    "                max_tokens = 300,\n",
    "                temperature = 0,\n",
    "#                 seed = 30\n",
    "        )\n",
    "    \n",
    "            ans1.append(result['choices'][0]['message']['content'])\n",
    "        \n",
    "        flag = False\n",
    "    except openai.error.RateLimitError as e:\n",
    "        print(f\"RateLimitError: {e}\")\n",
    "        time.sleep(60)\n",
    "        start_i = len(ans1)+0\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break  # Exit the loop on other errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ans1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"answer1\"] = ans1\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../experiment/OpenAI/generated_output.csv\",index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETD results\n",
    "\n",
    "df_test_random = pd.read_csv(\"../experiment/OpenAI/ETD/etd_random_V3_0example_gpt4o_result(t=0).csv\")\n",
    "predictions_etd = df_test_random[\"y''_ETD\"]\n",
    "y_test = df_test_random[\"y_ETD\"]\n",
    "precison_etd = mt.precision_score(y_test, predictions_etd)\n",
    "recall_etd = mt.recall_score(y_test, predictions_etd)\n",
    "score_etd = mt.f1_score(y_test, predictions_etd)\n",
    "\n",
    "print(\"precision:\",round(precison_etd,3),\"recall:\",round(recall_etd,3),\"F1:\",round(score_etd,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS results \n",
    "\n",
    "df_test_random = pd.read_csv(\"../experiment/OpenAI/PS/ps_random_avg_V3_10example_gpt4o_result(t=0).csv\")\n",
    "predictions_ps = df_test_random[\"y''_PS\"]\n",
    "y_test = df_test_random[\"y_PS\"]\n",
    "precison_ps = mt.precision_score(y_test, predictions_ps)\n",
    "recall_ps = mt.recall_score(y_test, predictions_ps)\n",
    "score_ps = mt.f1_score(y_test, predictions_ps)\n",
    "\n",
    "print(\"precision:\",round(precison_ps,3),\"recall:\",round(recall_ps,3),\"F1:\",round(score_ps,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9817b186a29e4e9713184d901f26c1ee05ad25243d878baff7f31bb1fef480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
